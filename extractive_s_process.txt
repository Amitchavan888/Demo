import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from gensim.summarization import summarize

# Text paragraph
text_paragraph = """Hello all, Welcome to Python Programming Academy. Python Programming Academy is a nice platform to learn new programming skills. It is difficult to get enrolled in this Academy."""

# Preprocess the text to remove special characters and digits
def preprocess_text(text):
    # Remove special characters and digits
    processed_text = re.sub(r'[^a-zA-Z\s]', '', text)
    return processed_text

processed_text = preprocess_text(text_paragraph)

# Generate summary using extractive summarization
def generate_summary(text, ratio=0.2):
    # Tokenize the text into sentences
    sentences = sent_tokenize(text)
    
    # Join the sentences into a single string
    text = ' '.join(sentences)
    
    # Generate the summary
    summary = summarize(text, ratio=ratio)
    
    return summary

summary = generate_summary(processed_text)

print("Preprocessed Text:")
print(processed_text)
print("\nSummary:")
print(summary)
